[{"type": "faculty", "item": []}, {"type": "Ph.D. Students", "item": [{"name": "\u9a6c\u4ebf", "desc": 2020, "img": "assets/image/team/\u9a6c\u4ebf.jpg", "link": "https://mayi1996.top/", "area": "Offline Reinforcement Learning, RL for application"}, {"name": "\u674e\u9e4f\u7ffc", "desc": 2022, "img": "assets/image/team/\u674e\u9e4f\u7ffc.jpg", "link": "github.com/yeshenpy", "area": "\u6f14\u5316\u5f3a\u5316\u5b66\u4e60\uff0c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60"}, {"name": "\u5218\u91d1\u6bc5", "desc": 2022, "img": "assets/image/team/\u5218\u91d1\u6bc5.jpg", "link": "https://scholar.google.com/citations?user=kaQS7NAAAAAJ", "area": "LLM for Control, Offline Reinforcement Learning"}, {"name": "\u502a\u98de", "desc": 2021, "img": "assets/image/team/\u502a\u98de.jpg", "link": "https://fei-ni.github.io", "area": "Model based RL; Diffusion for RL; LLM"}, {"name": "\u5f20\u654f", "desc": 2020, "img": "assets/image/team/\u5f20\u654f.jpg", "link": "", "area": "Self-Supervised Reinforcement Learning"}, {"name": "\u8881\u9038\u592b", "desc": 2023, "img": "assets/image/team/\u8881\u9038\u592b.jpg", "link": "", "area": "Model Based RL; Reinforcement with Human Feedback; Generative Models"}, {"name": "\u90dd\u6653\u7530", "desc": 2020, "img": "assets/image/team/\u90dd\u6653\u7530.jpg", "link": "", "area": "Reinforcement Learning, Multiagent system"}]}, {"type": "Graduate Students", "item": [{"name": "\u674e\u4f9d\u5b81", "desc": 2022, "img": "assets/image/team/\u674e\u4f9d\u5b81.jpg", "link": "", "area": "transfer learning"}, {"name": "\u5085\u8d24", "desc": 2022, "img": "assets/image/team/\u5085\u8d24.jpg", "link": "", "area": "Reinfocement Learning, Evolutionary Reinfocement Learning"}, {"name": "\u5218\u5609\u987a", "desc": 2022, "img": "assets/image/team/\u5218\u5609\u987a.jpg", "link": "", "area": "Large language models, real time control"}, {"name": "\u5bc7\u9f99\u99a8", "desc": 2023, "img": "assets/image/team/\u5bc7\u9f99\u99a8.jpg", "link": "", "area": "Deep Reinforcement Learning; Deep Learning; LLM"}, {"name": "\u97e9\u6c9b\u9f99", "desc": 2023, "img": "assets/image/team/\u97e9\u6c9b\u9f99.jpg", "link": "", "area": "MA"}, {"name": "\u51af\u4e4b\u6b23", "desc": 2023, "img": "assets/image/team/\u51af\u4e4b\u6b23.jpg", "link": "", "area": "RLHF"}, {"name": "\u8463\u5b50\u658c", "desc": 2023, "img": "assets/image/team/\u8463\u5b50\u658c.jpg", "link": "", "area": "Model Based Reinforcement Learning; Generative Models; Diffusion Models for Decision Making"}, {"name": "\u9648\u9038\u5f6c", "desc": 2023, "img": "assets/image/team/\u9648\u9038\u5f6c.jpg", "link": "", "area": "RLHF LLM"}, {"name": "\u5f20\u8c6a", "desc": 2022, "img": "assets/image/team/\u5f20\u8c6a.jpg", "link": "", "area": "Transfer reinforcement learning"}, {"name": "\u5434\u5409\u6d32", "desc": 2021, "img": "assets/image/team/\u5434\u5409\u6d32.jpg", "link": "https://github.com/Cubism-star", "area": "Deep Reinforcement Learning, Transfer learning"}, {"name": "\u8fde\u58eb\u7199", "desc": 2022, "img": "assets/image/team/\u8fde\u58eb\u7199.jpg", "link": "", "area": "Offline RL"}, {"name": "\u80e1\u8096\u6c49", "desc": 2021, "img": "assets/image/team/\u80e1\u8096\u6c49.jpg", "link": "", "area": "Offline reinforcement learning"}, {"name": "\u8d75\u6977", "desc": 2021, "img": "assets/image/team/\u8d75\u6977.jpg", "link": "", "area": "Offline Reinforcement Learning"}, {"name": "\u7b26\u51cc\u667a", "desc": 2023, "img": "assets/image/team/\u7b26\u51cc\u667a.jpg", "link": "", "area": "Reinforcement Learning, Representation Learning"}, {"name": "\u77f3\u78ca", "desc": 2022, "img": "assets/image/team/\u77f3\u78ca.jpg", "link": "", "area": "Self-supervised Reinforcement Learning"}, {"name": "\u6881\u8d3a\u658c", "desc": 2023, "img": "assets/image/team/\u6881\u8d3a\u658c.jpg", "link": "", "area": "Offline Reinforcement Learning"}]}, {"type": "Alumni", "item": []}]